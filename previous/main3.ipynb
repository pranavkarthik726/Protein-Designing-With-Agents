{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee0a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM value is already an LLM object\n",
      "LLM value is already an LLM object\n",
      "LLM value is already an LLM object\n",
      "LLM value is already an LLM object\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92muniprot_query_generator\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Extract key biological terms from the protein function description: I want a protein that can help in DNA binding..\n",
      "2. Map these terms to UniProt search fields and controlled vocabularies.\n",
      "3. Generate a structured UniProt query optimized for accuracy and recall.\n",
      "4. Validate and refine the query to ensure relevant search results.\u001b[00m\n",
      "Requesting URL: https://rest.uniprot.org/uniprotkb/search?format=json&query=%28%28cc_function%3A%22DNA%20binding%22%29%29&size=1\n",
      "Data saved to uniprot_DNA_binding.json\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92muniprot_query_generator\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mUniProt Fetcher\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"function_keyword\\\": \\\"DNA binding\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "{'results': [{'entryType': 'UniProtKB unreviewed (TrEMBL)', 'primaryAccession': 'A0A0D6KZJ4', 'uniProtkbId': 'A0A0D6KZJ4_9CYAN', 'entryAudit': {'firstPublicDate': '2015-05-27', 'lastAnnotationUpdateDate': '2025-02-05', 'lastSequenceUpdateDate': '2015-05-27', 'entryVersion': 28, 'sequenceVersion': 1}, 'annotationScore': 2.0, 'organism': {'scientificName': 'Tolypothrix sp. PCC 7601', 'taxonId': 1188, 'evidences': [{'evidenceCode': 'ECO:0000313', 'source': 'EMBL', 'id': 'EKF05267.1'}, {'evidenceCode': 'ECO:0000313', 'source': 'Proteomes', 'id': 'UP000032761'}], 'lineage': ['Bacteria', 'Bacillati', 'Cyanobacteriota', 'Cyanophyceae', 'Nostocales', 'Tolypothrichaceae', 'Tolypothrix']}, 'proteinExistence': '3: Inferred from homology', 'proteinDescription': {'recommendedName': {'fullName': {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': 'DNA-binding transcriptional activator HetR'}, 'ecNumbers': [{'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': '3.4.21.-'}]}, 'alternativeNames': [{'fullName': {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': 'Heterocyst differentiation control protein'}}]}, 'genes': [{'geneName': {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': 'hetR'}, 'orfNames': [{'evidences': [{'evidenceCode': 'ECO:0000313', 'source': 'EMBL', 'id': 'EKF05267.1'}], 'value': 'FDUTEX481_01438'}]}], 'comments': [{'texts': [{'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': 'Controls heterocyst differentiation. Dimerization is required for DNA-binding. Has both a protease and a DNA-binding activity'}], 'commentType': 'FUNCTION'}, {'texts': [{'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': 'Homodimer; disulfide-linked'}], 'commentType': 'SUBUNIT'}, {'texts': [{'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'value': 'Belongs to the peptidase S48 family'}], 'commentType': 'SIMILARITY'}, {'texts': [{'evidences': [{'evidenceCode': 'ECO:0000313', 'source': 'EMBL', 'id': 'EKF05267.1'}], 'value': 'The sequence shown here is derived from an EMBL/GenBank/DDBJ whole genome shotgun (WGS) entry which is preliminary data'}], 'commentType': 'CAUTION'}], 'features': [{'type': 'Domain', 'location': {'start': {'value': 219, 'modifier': 'EXACT'}, 'end': {'value': 297, 'modifier': 'EXACT'}}, 'description': 'HetR C-terminal Hood', 'evidences': [{'evidenceCode': 'ECO:0000259', 'source': 'Pfam', 'id': 'PF18460'}]}, {'type': 'Active site', 'location': {'start': {'value': 152, 'modifier': 'EXACT'}, 'end': {'value': 152, 'modifier': 'EXACT'}}, 'description': '', 'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}]}, {'type': 'Disulfide bond', 'location': {'start': {'value': 48, 'modifier': 'EXACT'}, 'end': {'value': 48, 'modifier': 'EXACT'}}, 'description': 'Interchain', 'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}]}], 'keywords': [{'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00023159'}, {'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-0010', 'category': 'Molecular function', 'name': 'Activator'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00023157'}, {'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-1015', 'category': 'PTM', 'name': 'Disulfide bond'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00023125'}, {'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-0238', 'category': 'Molecular function', 'name': 'DNA-binding'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-0364', 'category': 'Developmental stage', 'name': 'Heterocyst'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00022801'}, {'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-0378', 'category': 'Molecular function', 'name': 'Hydrolase'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00022670'}, {'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-0645', 'category': 'Molecular function', 'name': 'Protease'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00022825'}, {'evidenceCode': 'ECO:0000256', 'source': 'HAMAP-Rule', 'id': 'MF_00781'}], 'id': 'KW-0720', 'category': 'Molecular function', 'name': 'Serine protease'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00023163'}], 'id': 'KW-0804', 'category': 'Biological process', 'name': 'Transcription'}, {'evidences': [{'evidenceCode': 'ECO:0000256', 'source': 'ARBA', 'id': 'ARBA00023015'}], 'id': 'KW-0805', 'category': 'Biological process', 'name': 'Transcription regulation'}], 'references': [{'referenceNumber': 1, 'citation': {'id': '25953173', 'citationType': 'journal article', 'authors': ['Yerrapragada S.', 'Shukla A.', 'Hallsworth-Pepin K.', 'Choi K.', 'Wollam A.', 'Clifton S.', 'Qin X.', 'Muzny D.', 'Raghuraman S.', 'Ashki H.', 'Uzman A.', 'Highlander S.K.', 'Fryszczyn B.G.', 'Fox G.E.', 'Tirumalai M.R.', 'Liu Y.', 'Kim S.', 'Kehoe D.M.', 'Weinstock G.M.'], 'citationCrossReferences': [{'database': 'PubMed', 'id': '25953173'}], 'title': 'Extreme Sensory Complexity Encoded in the 10-Megabase Draft Genome Sequence of the Chromatically Acclimating Cyanobacterium Tolypothrix sp. PCC 7601.', 'publicationDate': '2015', 'journal': 'Genome Announc.', 'firstPage': '0', 'lastPage': '0', 'volume': '3'}, 'referencePositions': ['NUCLEOTIDE SEQUENCE [LARGE SCALE GENOMIC DNA]'], 'referenceComments': [{'evidences': [{'evidenceCode': 'ECO:0000313', 'source': 'Proteomes', 'id': 'UP000032761'}], 'value': 'PCC 7601 / UTEX B 481', 'type': 'STRAIN'}], 'evidences': [{'evidenceCode': 'ECO:0000313', 'source': 'EMBL', 'id': 'EKF05267.1'}, {'evidenceCode': 'ECO:0000313', 'source': 'Proteomes', 'id': 'UP000032761'}]}], 'uniProtKBCrossReferences': [{'database': 'EMBL', 'id': 'AGCR01000005', 'properties': [{'key': 'ProteinId', 'value': 'EKF05267.1'}, {'key': 'Status', 'value': '-'}, {'key': 'MoleculeType', 'value': 'Genomic_DNA'}]}, {'database': 'RefSeq', 'id': 'WP_045868309.1', 'properties': [{'key': 'NucleotideSequenceId', 'value': 'NZ_JH930357.1'}]}, {'database': 'AlphaFoldDB', 'id': 'A0A0D6KZJ4', 'properties': [{'key': 'Description', 'value': '-'}]}, {'database': 'PATRIC', 'id': 'fig|1188.3.peg.1441', 'properties': [{'key': 'GeneDesignation', 'value': '-'}]}, {'database': 'HOGENOM', 'id': 'CLU_926376_0_0_3', 'properties': [{'key': 'Description', 'value': '-'}]}, {'database': 'OrthoDB', 'id': '526832at2', 'properties': [{'key': 'Description', 'value': '-'}]}, {'database': 'Proteomes', 'id': 'UP000032761', 'properties': [{'key': 'Component', 'value': 'Unassembled WGS sequence'}]}, {'database': 'GO', 'id': 'GO:0003677', 'properties': [{'key': 'GoTerm', 'value': 'F:DNA binding'}, {'key': 'GoEvidenceType', 'value': 'IEA:UniProtKB-UniRule'}]}, {'database': 'GO', 'id': 'GO:0004252', 'properties': [{'key': 'GoTerm', 'value': 'F:serine-type endopeptidase activity'}, {'key': 'GoEvidenceType', 'value': 'IEA:UniProtKB-UniRule'}]}, {'database': 'GO', 'id': 'GO:0043158', 'properties': [{'key': 'GoTerm', 'value': 'P:heterocyst development'}, {'key': 'GoEvidenceType', 'value': 'IEA:UniProtKB-UniRule'}]}, {'database': 'GO', 'id': 'GO:0006508', 'properties': [{'key': 'GoTerm', 'value': 'P:proteolysis'}, {'key': 'GoEvidenceType', 'value': 'IEA:UniProtKB-KW'}]}, {'database': 'Gene3D', 'id': '6.10.250.2740', 'properties': [{'key': 'EntryName', 'value': '-'}, {'key': 'MatchStatus', 'value': '1'}]}, {'database': 'Gene3D', 'id': '1.10.10.1670', 'properties': [{'key': 'EntryName', 'value': 'HetR, flap domain'}, {'key': 'MatchStatus', 'value': '1'}]}, {'database': 'Gene3D', 'id': '1.10.10.1680', 'properties': [{'key': 'EntryName', 'value': 'HetR, N-terminal DNA-binding domain'}, {'key': 'MatchStatus', 'value': '1'}]}, {'database': 'HAMAP', 'id': 'MF_00781', 'properties': [{'key': 'EntryName', 'value': 'HetR'}, {'key': 'MatchStatus', 'value': '1'}]}, {'database': 'InterPro', 'id': 'IPR040949', 'properties': [{'key': 'EntryName', 'value': 'HetR_C'}]}, {'database': 'InterPro', 'id': 'IPR041936', 'properties': [{'key': 'EntryName', 'value': 'HetR_DNA-bd_N'}]}, {'database': 'InterPro', 'id': 'IPR041935', 'properties': [{'key': 'EntryName', 'value': 'HetR_flap'}]}, {'database': 'InterPro', 'id': 'IPR005319', 'properties': [{'key': 'EntryName', 'value': 'Pept_S48_HetR'}]}, {'database': 'Pfam', 'id': 'PF18460', 'properties': [{'key': 'EntryName', 'value': 'HetR_C'}, {'key': 'MatchStatus', 'value': '1'}]}, {'database': 'Pfam', 'id': 'PF03574', 'properties': [{'key': 'EntryName', 'value': 'Peptidase_S48'}, {'key': 'MatchStatus', 'value': '1'}]}], 'sequence': {'value': 'MSNDIDLIKRLGPSAMDQIMLYLAFSAMRTSGHRHGAFLDAAATAAKCAIYMTYLEQGQNLRMTGHLHHLEPKRVKIIVEEVRQALTEGKLLKMLGSQEPRYLIQLPYVWMEKFPWRPGKSRIPGTSLTTEEKKQIEHKLPSNLPDAQLITSFEFLELIEFLHKRSQEEMPPEHQMPLSEALAEHIKRRLLYSGTVTRIDSPWGMPFYALTRPFYAPADDQERTYIMVEDTARYFRLMKDWAEKRQNAMRALEELDIPPERLEQALEELDEVIRAWADRYHQEGGVPMILQMVFGKKED', 'length': 299, 'molWeight': 34828, 'crc64': '2538101865869426', 'md5': 'C06BA3E6CEAED0E2508E379B522959DB'}, 'extraAttributes': {'countByCommentType': {'FUNCTION': 1, 'SUBUNIT': 1, 'SIMILARITY': 1, 'CAUTION': 1}, 'countByFeatureType': {'Domain': 1, 'Active site': 1, 'Disulfide bond': 1}, 'uniParcId': 'UPI0005EAB006'}}]}\u001b[00m\n",
      "\u001b[91m Received None or empty response from LLM call.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 14190, Requested 3048. Please try again in 8.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13998, Requested 3048. Please try again in 8.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13836, Requested 3048. Please try again in 7.534s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13667, Requested 3048. Please try again in 6.858s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13510, Requested 3048. Please try again in 6.23s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13356, Requested 3048. Please try again in 5.615s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13170, Requested 3048. Please try again in 4.87s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 13005, Requested 3048. Please try again in 4.211999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12827, Requested 3048. Please try again in 3.497s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12627, Requested 3048. Please try again in 2.697s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12457, Requested 3048. Please try again in 2.017999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12273, Requested 3048. Please try again in 1.284s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 12107, Requested 3048. Please try again in 619ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92muniprot_query_generator\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mUniProt Fetcher\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"function_keyword\\\": \\\"DNA binding\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "I tried reusing the same input, I must stop using this action input. I'll try something else instead.\n",
      "\n",
      "\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 17162, Requested 3119. Please try again in 21.125s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 17009, Requested 3119. Please try again in 20.515s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 16850, Requested 3119. Please try again in 19.876s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 16653, Requested 3119. Please try again in 19.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `gemma2-9b-it` in organization `org_01jnzbwaptee1s9tnfbn21hknk` service tier `on_demand` on tokens per minute (TPM): Limit 15000, Used 16493, Requested 3119. Please try again in 18.45s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 217\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Kickoff the combined crew workflow with the updated inputs\u001b[39;00m\n\u001b[0;32m    212\u001b[0m combined_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muserinput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI want a protein that can help in DNA binding.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m }\n\u001b[1;32m--> 217\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_crew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombined_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\crew.py:551\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    548\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[1;32m--> 551\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[0;32m    553\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\crew.py:658\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[0;32m    657\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\crew.py:760\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[1;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[0;32m    757\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m    759\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[1;32m--> 760\u001b[0m task_output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m task_outputs \u001b[38;5;241m=\u001b[39m [task_output]\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\task.py:302\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[1;34m(self, agent, context, tools)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    297\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    298\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    299\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[0;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\task.py:366\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[1;34m(self, agent, context, tools)\u001b[0m\n\u001b[0;32m    362\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[1;32m--> 366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[0;32m    373\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[0;32m    374\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    375\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[0;32m    382\u001b[0m )\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\agent.py:255\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[1;34m(self, task, context, tools)\u001b[0m\n\u001b[0;32m    252\u001b[0m     task_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_trained_data(task_prompt\u001b[38;5;241m=\u001b[39mtask_prompt)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mask_for_human_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:101\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_start_logs()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m--> 101\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input:\n\u001b[0;32m    104\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_human_feedback(formatted_answer)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:126\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_rpm_limit()\n\u001b[1;32m--> 126\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_llm_response(answer)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\agents\\crew_agent_executor.py:163\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_llm_response\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[0;32m    169\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[0;32m    170\u001b[0m             content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    171\u001b[0m             color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    172\u001b[0m         )\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\crewai\\llm.py:219\u001b[0m, in \u001b[0;36mLLM.call\u001b[1;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[0;32m    194\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,  \u001b[38;5;66;03m# pass the tool schema\u001b[39;00m\n\u001b[0;32m    215\u001b[0m }\n\u001b[0;32m    217\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m--> 219\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m response_message \u001b[38;5;241m=\u001b[39m cast(Choices, cast(ModelResponse, response)\u001b[38;5;241m.\u001b[39mchoices)[\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    222\u001b[0m ]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m    223\u001b[0m text_response \u001b[38;5;241m=\u001b[39m response_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\litellm\\utils.py:900\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    898\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    899\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    901\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\litellm\\main.py:1462\u001b[0m, in \u001b[0;36mcompletion\u001b[1;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[0;32m   1457\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1458\u001b[0m             k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m optional_params\n\u001b[0;32m   1459\u001b[0m         ):  \u001b[38;5;66;03m# completion(top_k=3) > openai_config(top_k=3) <- allows for dynamic variables to be passed in\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m             optional_params[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m-> 1462\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_chat_completions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[0;32m   1478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maiohttp_openai\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;66;03m# NEW aiohttp provider for 10-100x higher RPS\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m     api_base \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1484\u001b[0m         api_base  \u001b[38;5;66;03m# for deepinfra/perplexity/anyscale/groq/friendliai we check in get_llm_provider and pass in the api base from there\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mapi_base\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m get_secret(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_BASE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1487\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1488\u001b[0m     )\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\litellm\\llms\\groq\\chat\\handler.py:55\u001b[0m, in \u001b[0;36mGroqChatCompletion.completion\u001b[1;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     fake_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreaming_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreaming_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfake_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\litellm\\llms\\openai_like\\chat\\handler.py:367\u001b[0m, in \u001b[0;36mOpenAILikeChatHandler.completion\u001b[1;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[0;32m    365\u001b[0m     client \u001b[38;5;241m=\u001b[39m HTTPHandler(timeout\u001b[38;5;241m=\u001b[39mtimeout)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 367\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\litellm\\llms\\custom_httpx\\http_handler.py:508\u001b[0m, in \u001b[0;36mHTTPHandler.post\u001b[1;34m(self, url, data, json, params, headers, stream, timeout, files, content)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, files\u001b[38;5;241m=\u001b[39mfiles, content\u001b[38;5;241m=\u001b[39mcontent  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     )\n\u001b[1;32m--> 508\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\ssl.py:1295\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1293\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\bio\\Lib\\ssl.py:1168\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "from pydantic import BaseModel\n",
    "from crewai.tools.structured_tool import CrewStructuredTool\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Part 1: UniProt Query Generation Workflow\n",
    "# -----------------------------------------------\n",
    "\n",
    "def get_uniprot(function_keyword: str):\n",
    "    if not function_keyword:\n",
    "        raise ValueError(\"Function keyword must be a non-empty string.\")\n",
    "    # Build and encode the query\n",
    "    query = f'((cc_function:\"{function_keyword}\"))'\n",
    "    encoded_query = urllib.parse.quote(query)\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/search?format=json&query={encoded_query}&size=1\"\n",
    "    print(\"Requesting URL:\", url)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        print(\"Error querying UniProt:\", e)\n",
    "        return None\n",
    "    if not data:\n",
    "        print(\"No UniProt entries found for function:\", function_keyword)\n",
    "        return None\n",
    "    # Save the data to a new JSON file\n",
    "    filename = f\"uniprot_{function_keyword.replace(' ', '_')}.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "    return data\n",
    "\n",
    "# Define the schema for the tool's input\n",
    "class UniprotInput(BaseModel):\n",
    "    function_keyword: str\n",
    "\n",
    "# Wrapper for the UniProt tool\n",
    "def uniprot_tool_wrapper(function_keyword: str) -> dict:\n",
    "    result = get_uniprot(function_keyword)\n",
    "    if result is None:\n",
    "        return {\"error\": \"No data found or an error occurred while querying UniProt.\"}\n",
    "    return result\n",
    "\n",
    "# Create the structured tool for UniProt querying\n",
    "def create_uniprot_tool():\n",
    "    return CrewStructuredTool.from_function(\n",
    "        name=\"UniProt Fetcher\",\n",
    "        description=\"Fetches UniProt entries based on a function keyword using the UniProt REST API.\",\n",
    "        args_schema=UniprotInput,\n",
    "        func=uniprot_tool_wrapper,\n",
    "    )\n",
    "\n",
    "uniprot_tool = create_uniprot_tool()\n",
    "\n",
    "# Set API key and instantiate LLM for query generation\n",
    "GROQ_API_KEY = \"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\"\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"groq/gemma2-9b-it\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Agent to generate a UniProt query from a protein function description\n",
    "query_generator = Agent(\n",
    "    role=\"uniprot_query_generator\",\n",
    "    goal=\"Generates a UniProt query from a given protein function: {userinput}. Ensure the query retrieves relevant proteins\",\n",
    "    backstory=\"Designed as a highly specialized bioinformatics assistant to construct precise UniProt queries.\",\n",
    "    tools=[uniprot_tool],\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    "    output_pydantic=UniprotInput\n",
    ")\n",
    "\n",
    "# Agent to validate and refine the generated UniProt query\n",
    "uniprot_query_assurance_agent = Agent(\n",
    "    role=\"query_assurance_agent\",\n",
    "    goal=\"Ensures the generated UniProt query is accurate and relevant to the protein function: {userinput}. Verify that the query retrieves the correct proteins and aligns with the intended function.\",\n",
    "    backstory=\"This agent acts as a quality control specialist for bioinformatics queries, ensuring that the query targets the right proteins.\",\n",
    "    tools=[uniprot_tool],\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Define tasks for the UniProt query workflow\n",
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Extract key biological terms from the protein function description: {userinput}.\\n\"\n",
    "        \"2. Map these terms to UniProt search fields and controlled vocabularies.\\n\"\n",
    "        \"3. Generate a structured UniProt query optimized for accuracy and recall.\\n\"\n",
    "        \"4. Validate and refine the query to ensure relevant search results.\"\n",
    "    ),\n",
    "    expected_output=\"UniProt query for the given protein function description\",\n",
    "    agent=query_generator\n",
    ")\n",
    "\n",
    "query_review = Task(\n",
    "    description=\"Review the UniProt query generated by the uniprot_query_generator agent.\",\n",
    "    expected_input=\"A UniProt query string generated from a protein function description, along with the original user input.\",\n",
    "    expected_output=(\"A validation report stating whether the query is accurate and retrieves relevant proteins. \"\n",
    "                     \"If the query is suboptimal, provide suggestions to improve it.\"),\n",
    "    steps=[\n",
    "        \"Receive the generated UniProt query and the original protein function description.\",\n",
    "        \"Submit the query to the UniProt database using uniprot_tool.\",\n",
    "        \"Analyze the retrieved proteins and compare their functions to the intended protein function.\",\n",
    "        \"Identify mismatches or overly broad results.\",\n",
    "        \"Approve the query if highly accurate, otherwise provide improvement suggestions.\"\n",
    "    ],\n",
    "    acceptance_criteria=[\n",
    "        \"The query retrieves proteins that strongly match the intended function.\",\n",
    "        \"The query does not produce irrelevant or overly broad results.\",\n",
    "        \"Suggestions for improvement are practical and enhance query precision.\",\n",
    "        \"The validation report clearly explains the decision.\"\n",
    "    ],\n",
    "    agent=uniprot_query_assurance_agent\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Part 2: RF Diffusion Control Workflow\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Disable CrewAI telemetry if necessary\n",
    "os.environ[\"CREWAI_DISABLE_TELEMETRY\"] = \"true\"\n",
    "\n",
    "# Define the tool to fetch protein site information from cache\n",
    "from crewai.tools import tool\n",
    "\n",
    "@tool(\"get_protein__site_info\")\n",
    "def get_protein__site_info(protein_id: str) -> str:\n",
    "    \"\"\"Fetches the protein site information from cache.\"\"\"\n",
    "    loc = r\"cache\\uniprot\\{protein_id}.json\".format(protein_id=protein_id)\n",
    "    with open(loc, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        print(\"used\")\n",
    "        return str(data['results'][0]['features'])\n",
    "    print(\"No data found\")\n",
    "    return None\n",
    "\n",
    "# Load RF Diffusion manual context from file\n",
    "rf_diff_context_path = r\"Protein-Designing-With-Agents\\config\\RF_diff_context.txt\"\n",
    "with open(rf_diff_context_path, 'r') as f:\n",
    "    RF_Dif_manual = f.read()\n",
    "\n",
    "# Set Gemini API key and instantiate Gemini LLM for protein design tasks\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDQSOPPaW8BVWXny1ycBfO_tF9jJiYiuag\"\n",
    "gemini_llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Agent for protein scaffolding analysis based on UniProt features\n",
    "protein_expert_agent = Agent(\n",
    "    role=\"Protein Scaffolding Specialist\",\n",
    "    goal=\"Assist in creating protein scaffolds by identifying which motifs should be masked or preserved based on UniProt features.\",\n",
    "    backstory=\"Expert in computational protein design with experience in analyzing protein structural and functional data.\",\n",
    "    llm=gemini_llm,\n",
    "    tool=[get_protein__site_info],\n",
    "    tools_verbose=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent for translating protein analysis into RF Diffusion configuration strategies\n",
    "RF_Diffusion_Expert = Agent(\n",
    "    role=\"RF Diffusion Expert\",\n",
    "    goal=(\"Translate the protein scaffolding requirements into specific RF Diffusion implementation strategies, \"\n",
    "          \"specifying which motifs to mask versus preserve and providing technical details.\"),\n",
    "    backstory=\"Expert in diffusion-based generative modeling for protein design. Manual context: {RF_Dif_manual}\".format(RF_Dif_manual=RF_Dif_manual),\n",
    "    llm=gemini_llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Task for analyzing protein UniProt features and determining motif preservation/masking.\n",
    "# Updated to use the \"session\" input key instead of separate \"protein\" and \"function\" keys.\n",
    "protein_analysis_task = Task(\n",
    "    description=(\"Analyze the provided UniProt features in JSON format, identifying all functional sites (active sites, binding sites, metal-binding sites, etc.). \"\n",
    "                 \"Interpret the user's desired protein function based on the session identifier: {session}. \"\n",
    "                 \"Determine which motifs should be preserved as anchors and which regions masked for redesign. \"\n",
    "                 \"Identify the most appropriate scaffolding approach and provide clear reasoning for your decisions, including motif positions. \"\n",
    "                 \"The session identifier should be used to look up the corresponding protein details.\"),\n",
    "    expected_output=(\"A detailed JSON report containing an analysis of UniProt features, \"\n",
    "                     \"the identified motifs to be preserved or masked with justification, \"\n",
    "                     \"and the recommended scaffolding approach.\"),\n",
    "    agent=protein_expert_agent\n",
    ")\n",
    "\n",
    "# Task for generating the RF Diffusion configuration script based on the protein analysis\n",
    "RF_Diffusion_configuration_task = Task(\n",
    "    description=(\"Using the analysis from the previous task, generate a configuration script for running the RF Diffusion process. \"\n",
    "                 \"Include model settings, diffusion parameters, input file paths, output directory locations, \"\n",
    "                 \"and any optional parameters (such as contigmap).\"),\n",
    "    expected_output=\"A valid terminal script containing the RF Diffusion configuration with all necessary parameters.\",\n",
    "    agent=RF_Diffusion_Expert,\n",
    "    context=[protein_analysis_task]\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Combine all Agents and Tasks into a Single Crew\n",
    "# -----------------------------------------------\n",
    "\n",
    "combined_crew = Crew(\n",
    "    agents=[query_generator, uniprot_query_assurance_agent, protein_expert_agent, RF_Diffusion_Expert],\n",
    "    tasks=[plan, query_review, protein_analysis_task, RF_Diffusion_configuration_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Kickoff the combined crew workflow with the updated inputs\n",
    "combined_inputs = {\n",
    "    \"userinput\": \"I want a protein that can help in DNA binding.\",\n",
    "    \"session\": \"01\"\n",
    "}\n",
    "\n",
    "result = combined_crew.kickoff(inputs=combined_inputs)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a67804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import urllib.parse\n",
    "from pydantic import BaseModel\n",
    "from crewai.tools.structured_tool import CrewStructuredTool\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Part 1: UniProt Query Generation Workflow\n",
    "# -----------------------------------------------\n",
    "\n",
    "def get_uniprot(function_keyword: str):\n",
    "    if not function_keyword:\n",
    "        raise ValueError(\"Function keyword must be a non-empty string.\")\n",
    "    # Build and encode the query\n",
    "    query = f'((cc_function:\"{function_keyword}\"))'\n",
    "    encoded_query = urllib.parse.quote(query)\n",
    "    url = f\"https://rest.uniprot.org/uniprotkb/search?format=json&query={encoded_query}&size=1\"\n",
    "    print(\"Requesting URL:\", url)\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        print(\"Error querying UniProt:\", e)\n",
    "        return None\n",
    "    if not data:\n",
    "        print(\"No UniProt entries found for function:\", function_keyword)\n",
    "        return None\n",
    "    # Save the data to a new JSON file\n",
    "    filename = f\"uniprot_{function_keyword.replace(' ', '_')}.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "    return data\n",
    "\n",
    "# Define the schema for the tool's input\n",
    "class UniprotInput(BaseModel):\n",
    "    function_keyword: str\n",
    "\n",
    "# Wrapper for the UniProt tool\n",
    "def uniprot_tool_wrapper(function_keyword: str) -> dict:\n",
    "    result = get_uniprot(function_keyword)\n",
    "    if result is None:\n",
    "        return {\"error\": \"No data found or an error occurred while querying UniProt.\"}\n",
    "    return result\n",
    "\n",
    "# Create the structured tool for UniProt querying\n",
    "def create_uniprot_tool():\n",
    "    return CrewStructuredTool.from_function(\n",
    "        name=\"UniProt Fetcher\",\n",
    "        description=\"Fetches UniProt entries based on a function keyword using the UniProt REST API.\",\n",
    "        args_schema=UniprotInput,\n",
    "        func=uniprot_tool_wrapper,\n",
    "    )\n",
    "\n",
    "uniprot_tool = create_uniprot_tool()\n",
    "\n",
    "# Instantiate Gemini LLM (used for both parts)\n",
    "gemini_llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Agent to generate a UniProt query from a protein function description using Gemini LLM\n",
    "query_generator = Agent(\n",
    "    role=\"uniprot_query_generator\",\n",
    "    goal=\"Generates a UniProt query from a given protein function: {userinput}. Ensure the query retrieves relevant proteins\",\n",
    "    backstory=\"Designed as a highly specialized bioinformatics assistant to construct precise UniProt queries.\",\n",
    "    tools=[uniprot_tool],\n",
    "    verbose=True,\n",
    "    llm=gemini_llm,\n",
    "    output_pydantic=UniprotInput\n",
    ")\n",
    "\n",
    "# Agent to validate and refine the generated UniProt query using Gemini LLM\n",
    "uniprot_query_assurance_agent = Agent(\n",
    "    role=\"query_assurance_agent\",\n",
    "    goal=\"Ensures the generated UniProt query is accurate and relevant to the protein function: {userinput}. Verify that the query retrieves the correct proteins and aligns with the intended function.\",\n",
    "    backstory=\"This agent acts as a quality control specialist for bioinformatics queries, ensuring that the query targets the right proteins.\",\n",
    "    tools=[uniprot_tool],\n",
    "    verbose=True,\n",
    "    llm=gemini_llm,\n",
    ")\n",
    "\n",
    "# Define tasks for the UniProt query workflow\n",
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Extract key biological terms from the protein function description: {userinput}.\\n\"\n",
    "        \"2. Map these terms to UniProt search fields and controlled vocabularies.\\n\"\n",
    "        \"3. Generate a structured UniProt query optimized for accuracy and recall.\\n\"\n",
    "        \"4. Validate and refine the query to ensure relevant search results.\"\n",
    "    ),\n",
    "    expected_output=\"UniProt query for the given protein function description\",\n",
    "    agent=query_generator\n",
    ")\n",
    "\n",
    "query_review = Task(\n",
    "    description=\"Review the UniProt query generated by the uniprot_query_generator agent.\",\n",
    "    expected_input=\"A UniProt query string generated from a protein function description, along with the original user input.\",\n",
    "    expected_output=(\"A validation report stating whether the query is accurate and retrieves relevant proteins. \"\n",
    "                     \"If the query is suboptimal, provide suggestions to improve it.\"),\n",
    "    steps=[\n",
    "        \"Receive the generated UniProt query and the original protein function description.\",\n",
    "        \"Submit the query to the UniProt database using uniprot_tool.\",\n",
    "        \"Analyze the retrieved proteins and compare their functions to the intended protein function.\",\n",
    "        \"Identify mismatches or overly broad results.\",\n",
    "        \"Approve the query if highly accurate, otherwise provide improvement suggestions.\"\n",
    "    ],\n",
    "    acceptance_criteria=[\n",
    "        \"The query retrieves proteins that strongly match the intended function.\",\n",
    "        \"The query does not produce irrelevant or overly broad results.\",\n",
    "        \"Suggestions for improvement are practical and enhance query precision.\",\n",
    "        \"The validation report clearly explains the decision.\"\n",
    "    ],\n",
    "    agent=uniprot_query_assurance_agent\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Part 2: RF Diffusion Control Workflow\n",
    "# -----------------------------------------------\n",
    "\n",
    "# Disable CrewAI telemetry if necessary\n",
    "os.environ[\"CREWAI_DISABLE_TELEMETRY\"] = \"true\"\n",
    "\n",
    "# Define the tool to fetch protein site information from cache\n",
    "from crewai.tools import tool\n",
    "\n",
    "@tool(\"get_protein__site_info\")\n",
    "def get_protein__site_info(protein_id: str) -> str:\n",
    "    \"\"\"Fetches the protein site information from cache.\"\"\"\n",
    "    loc = r\"C:\\Users\\91900\\Documents\\Engg\\Sem-4\\IBS\\Projects\\Protein-Designing-With-Agents\\cache\\uniprot\\{protein_id}.json\".format(protein_id=protein_id)\n",
    "    with open(loc, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        print(\"used\")\n",
    "        return str(data['results'][0]['features'])\n",
    "    print(\"No data found\")\n",
    "    return None\n",
    "\n",
    "# Load RF Diffusion manual context from file\n",
    "rf_diff_context_path = r\"C:\\Users\\91900\\Documents\\Engg\\Sem-4\\IBS\\Projects\\Protein-Designing-With-Agents\\config\\RF_diff_context.txt\"\n",
    "with open(rf_diff_context_path, 'r') as f:\n",
    "    RF_Dif_manual = f.read()\n",
    "\n",
    "# Agent for protein scaffolding analysis based on UniProt features using Gemini LLM\n",
    "protein_expert_agent = Agent(\n",
    "    role=\"Protein Scaffolding Specialist\",\n",
    "    goal=\"Assist in creating protein scaffolds by identifying which motifs should be masked or preserved based on UniProt features.\",\n",
    "    backstory=\"Expert in computational protein design with experience in analyzing protein structural and functional data.\",\n",
    "    llm=gemini_llm,\n",
    "    tool=[get_protein__site_info],\n",
    "    tools_verbose=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Agent for translating protein analysis into RF Diffusion configuration strategies using Gemini LLM\n",
    "RF_Diffusion_Expert = Agent(\n",
    "    role=\"RF Diffusion Expert\",\n",
    "    goal=(\"Translate the protein scaffolding requirements into specific RF Diffusion implementation strategies, \"\n",
    "          \"specifying which motifs to mask versus preserve and providing technical details.\"),\n",
    "    backstory=\"Expert in diffusion-based generative modeling for protein design. Manual context: {RF_Dif_manual}\",\n",
    "    llm=gemini_llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Task for analyzing protein UniProt features and determining motif preservation/masking.\n",
    "# Updated to use the \"session\" input key instead of separate \"protein\" and \"function\" keys.\n",
    "protein_analysis_task = Task(\n",
    "    description=(\"Analyze the provided UniProt features in JSON format, identifying all functional sites (active sites, binding sites, metal-binding sites, etc.). \"\n",
    "                 \"Interpret the user's desired protein function based on the session identifier: {session}. \"\n",
    "                 \"Determine which motifs should be preserved as anchors and which regions masked for redesign. \"\n",
    "                 \"Identify the most appropriate scaffolding approach and provide clear reasoning for your decisions, including motif positions. \"\n",
    "                 \"The session identifier should be used to look up the corresponding protein details.\"),\n",
    "    expected_output=(\"A detailed JSON report containing an analysis of UniProt features, \"\n",
    "                     \"the identified motifs to be preserved or masked with justification, \"\n",
    "                     \"and the recommended scaffolding approach.\"),\n",
    "    agent=protein_expert_agent\n",
    ")\n",
    "\n",
    "# Task for generating the RF Diffusion configuration script based on the protein analysis\n",
    "RF_Diffusion_configuration_task = Task(\n",
    "    description=(\"Using the analysis from the previous task, generate a configuration script for running the RF Diffusion process. \"\n",
    "                 \"Include model settings, diffusion parameters, input file paths, output directory locations, \"\n",
    "                 \"and any optional parameters (such as contigmap).\"),\n",
    "    expected_output=\"A valid terminal script containing the RF Diffusion configuration with all necessary parameters.\",\n",
    "    agent=RF_Diffusion_Expert,\n",
    "    context=[protein_analysis_task]\n",
    ")\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Combine all Agents and Tasks into a Single Crew\n",
    "# -----------------------------------------------\n",
    "\n",
    "combined_crew = Crew(\n",
    "    agents=[query_generator, uniprot_query_assurance_agent, protein_expert_agent, RF_Diffusion_Expert],\n",
    "    tasks=[plan, query_review, protein_analysis_task, RF_Diffusion_configuration_task],\n",
    "    verbose=True,\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "# Kickoff the combined crew workflow with the updated inputs\n",
    "combined_inputs = {\n",
    "    \"userinput\": \"I want a protein that can help in DNA binding.\",\n",
    "    \"session\": \"01\"\n",
    "    \n",
    "}\n",
    "\n",
    "result = combined_crew.kickoff(inputs=combined_inputs)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
